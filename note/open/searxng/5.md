# 第 5 章：结果类型与聚合

欢迎回来

在我们迄今为止的旅程中，我们已经看到**[搜索编排（处理器）](01_search_orchestration__processor__.md)**如何充当指挥，指导我们的搜索。我们已经了解了**[设置管理](02_settings_management_.md)**如何设置全局规则，以及**[用户偏好](03_user_preferences_.md)**如何让我们个性化我们的体验。最近，在**[引擎](04_engines_.md)**中，我们了解了各个搜索提供商（"音乐家"）如何接收我们的查询并返回原始结果。

但是，在所有这些不同的结果返回后会发生什么？SearXNG 如何组织它们、删除重复项并在我们的屏幕上以干净、统一的方式呈现它们？这就是**结果类型与聚合**的作用——它是==将一堆原始数据转换为美观、有组织的搜索结果页面的系统==

### 结果类型与聚合解决什么问题？

想象一下，我们搜索"埃菲尔铁塔高度"。我们可能期望：
*   直接说明高度的快速答案。
*   指向 Wikipedia 或旅游网站的标准网络链接。
*   也许是一个包含关键事实和铁塔图像的"信息框"。
*   也许是"埃菲尔铁塔历史"的建议。

每个**[引擎](04_engines__.md)**（如 Wikipedia、DuckDuckGo、用于事实的专用"回答器"或用于图像的插件）可能会以略微不同的格式返回其数据。如果没有标准化的方式来描述和处理这些不同类型的结果，SearXNG 将面临巨大的混乱：
*   我们如何知道一段文本是主要搜索结果标题，还是即时答案？
*   我们如何组合来自多个引擎的关于同一事物的结果而不显示重复项？
*   我们如何在一个页面上清楚地呈现所有这些不同*类型*的信息（网络链接、图像、即时事实）？

**结果类型与聚合**通过以下方式解决这个问题：
1.  **标准化**：为所有传入数据定义清晰的"类型"（如用于网络链接的 `MainResult` 或用于即时事实的 `Answer`），以便每个人都说同一种语言。
2.  **组织**：将相似的结果分组到搜索页面上的特定"区域"（如主列表、答案框或侧边栏信息框）。
3.  **聚合**：智能地合并来自不同来源的结果，删除重复项，并对它们进行评分以决定最佳顺序。

可以将其视为我们管弦乐队的舞台工作人员。他们从音乐家（引擎）那里接收所有不同的道具（原始结果），对它们进行分类，确保没有重复的道具，并在舞台（我们的搜索结果页面）上为观众（我们）完美地排列它们。

### 我们的搜索之旅：从原始数据到统一页面

让我们使用我们的"埃菲尔铁塔高度"示例。

1.  我们在 SearXNG 中输入"埃菲尔铁塔高度"。
2.  **[搜索编排](01_search_orchestration__processor__.md)**将我们的查询发送到相关的**[引擎](04_engines__.md)**（例如，"通用"网络引擎、"知识库"引擎，也许是"图像"引擎）。
3.  每个引擎返回其原始发现：
    *   DuckDuckGo 可能返回带有几个网络链接的 HTML。
    *   Wikipedia 引擎可能返回用于信息框的结构化数据。
    *   "事实"引擎可能返回"330 米（1,083 英尺）"作为纯字符串。
4.  每个**[引擎](04_engines__.md)**（或**[插件](06_plugins__.md)**或**回答器**）将其原始发现转换为标准化的 SearXNG **结果类型**。例如：
    *   事实"330 米"变成一个 `Answer` 对象。
    *   网络链接变成一个 `MainResult` 对象。
    *   Wikipedia 数据变成一个 `Infobox` 结果（目前也是 `LegacyResult`，但将来会成为适当的类型）。
5.  然后，所有这些类型化的结果都被收集到一个名为 `ResultContainer` 的特殊容器中。
6.  `ResultContainer` 然后发挥其魔力：
    *   它检查重复的 `MainResult` 项（例如，如果 DuckDuckGo 和 Bing 都返回了相同的 Wikipedia 链接）。如果找到，它会合并它们。
    *   它收集所有 `Answer` 项。
    *   它收集所有 `Infobox` 项。
    *   它对 `MainResult` 项进行分组以确保平衡显示（例如，不是所有来自一个引擎的结果都在顶部）。
7.  最后，`ResultContainer` 将组织和聚合的结果交给显示系统，该系统将它们渲染成单个、连贯的搜索结果页面。

### 概念

让我们分解这个系统背后的主要思想。

#### 1. 标准化结果类型

SearXNG 为所有结果定义了一种通用语言，无论其来源如何。这使得处理和显示它们变得更加容易。

*   **`Result`（基础）**：这是最基本的构建块。每个其他结果类型都继承自 `Result`。它包括基本字段，如 `url`（链接）和 `engine`（哪个引擎找到了它）。

    ```python
    # 简化自 searx/result_types/_base.py
    import msgspec
    import urllib.parse
    import typing as t

    class Result(msgspec.Struct, kw_only=True):
        url: str | None = None  # 与此结果相关的链接
        engine: str | None = "" # 此结果来自的引擎名称
        parsed_url: urllib.parse.ParseResult | None = None # URL 的解析版本
        # ... 其他基本字段
    ```
    -   `msgspec.Struct`：这使 `Result` 成为一个非常高效的数据结构。
    -   `url` 和 `engine`：每个结果在其核心可能有一个 URL 并知道其来源。

*   **`MainResult`（标准网络链接）**：这是用于我们在搜索页面上看到的熟悉的蓝色链接。它在 `Result` 的基础上构建，具有 `title`、`content`（描述）和 `img_src`（用于关联图像）等字段。

    ```python
    # 简化自 searx/result_types/_base.py
    class MainResult(Result):
        template: str = "default.html" # 要使用哪个 HTML 模板
        title: str = ""                # 链接标题
        content: str = ""              # 描述/摘要
        img_src: str = ""              # 图像的 URL
        priority: t.Literal["", "high", "low"] = "" # 用于排名
        engines: set[str] = set()      # 找到此结果的所有引擎
        # ... 许多其他特定于主搜索结果的字段
    ```
    -   `title` 和 `content`：这些是我们主要看到的网络结果。
    -   `engines`：这对聚合很重要！如果多个引擎找到*相同*的结果，它们的名称会添加到这个集合中。

*   **`Answer` 和 `WeatherAnswer`（即时信息）**：这些用于简短、直接的答案，如"埃菲尔铁塔高度"示例。`WeatherAnswer` 是用于天气数据的专门 `Answer`。

    ```python
    # 简化自 searx/result_types/answer.py
    class BaseAnswer(Result, kw_only=True):
        # 所有答案类型的基类
        pass

    class Answer(BaseAnswer, kw_only=True):
        template: str = "answer/legacy.html"
        answer: str # 答案的实际文本
        # ... 来自 BaseAnswer 的可选 URL 字段
    ```
    -   `answer`：此字段直接保存快速事实或响应。

*   **`LegacyResult`（用于过去）**：过去，SearXNG 使用普通的 Python 字典来表示结果。`LegacyResult` 是一个特殊的包装器，使这些旧式字典的行为有点像新的类型化结果。它被标记为弃用，*不应*在新的引擎或插件开发中使用。其目的是确保旧引擎在 SearXNG 过渡到完全类型化结果时仍能工作。

    ```python
    # 简化自 searx/result_types/_base.py
    import warnings
    
    class LegacyResult(dict[str, t.Any]):
        # 旧结果项（字典）的包装器
        # ... 它模拟 url、title、content 等字段
        # ... 并警告开发人员它已被弃用
        def __init__(self, *args: t.Any, **kwargs: t.Any):
            super().__init__(*args, **kwargs)
            warnings.warn("使用已弃用的 `dict` 作为结果。迁移到类型化的 Result 类。", DeprecationWarning)
            # ... 将字典键映射到预期字段的内部逻辑
    ```
    -   `warnings.warn`：这一行是对开发人员的明确信号，要求他们不再使用此类型。

#### 2. 结果区域

SearXNG 不仅按类型对结果进行分类，还按它们应该出现在搜索页面上的位置进行分类。这在 `docs/dev/result_types/index.rst` 文件中描述。

| 区域名称     | 描述                                                | 常见结果类型                                          |
| :----------- | :-------------------------------------------------- | :---------------------------------------------------- |
| **主要结果** | 网络链接、文章、图像等的主要列表。                  | `MainResult`、`Paper`、`File`                         |
| **答案**     | 突出显示的简短、直接答案。                          | `Answer`、`Translations`、`WeatherAnswer`、`Code`     |
| **信息框**   | 附加信息，通常在侧边栏中，如 Wikipedia 摘要或地图。 | `LegacyResult`（很快将成为适当的 `InfoboxResult`）    |
| **建议**     | 替代搜索词或相关查询。                              | `LegacyResult`（很快将成为适当的 `SuggestionResult`） |
| **更正**     | 拼写更正建议（例如，"您是说...？"）。               | `LegacyResult`（很快将成为适当的 `CorrectionResult`） |

所有来源（引擎、插件、回答器）都可以为这些区域中的任何一个做出贡献，提供了极大的灵活性。

#### 3. `ResultContainer`（中央聚合器）

`ResultContainer`（在 `searx/results.py` 中找到）是主要的组织者。它就像一个大篮子，所有来源的所有结果都被扔进去。它的工作是收集它们、处理它们并为显示做好准备。

```python
# 简化自 searx/results.py
from threading import RLock
from searx.result_types import Result, LegacyResult, MainResult
from searx.result_types.answer import AnswerSet, BaseAnswer

class ResultContainer:
    main_results_map: dict[int, MainResult | LegacyResult] # 存储唯一的主要结果
    infoboxes: list[LegacyResult]                       # 存储信息框
    suggestions: set[str]                               # 存储唯一的建议
    answers: AnswerSet                                  # 存储唯一的答案
    corrections: set[str]                               # 存储唯一的更正
    timings: list[Timing]                               # 每个引擎花费的时间
    # ... 其他内部数据

    def __init__(self):
        self.main_results_map = {}
        self.infoboxes = []
        self.suggestions = set()
        self.answers = AnswerSet() # AnswerSet 处理自己的去重
        self.corrections = set()
        self.unresponsive_engines: set[UnresponsiveEngine] = set()
        self.timings = []
        self._lock: RLock = RLock() # 用于从多个线程安全访问
        # ...
```
-   `main_results_map`：这是一个字典，其中键是结果的 `hash`（用于查找重复项），值是 `MainResult` 对象。
-   `AnswerSet`：一个特殊的类，确保只存储唯一的 `Answer` 对象。
-   `_lock`：对于线程安全很重要，因为多个**[EngineProcessors](01_search_orchestration__processor__.md)**并发添加结果。

#### 4. 聚合逻辑：去重、合并和评分

`ResultContainer` 使用几种巧妙的技术来提供干净且全面的搜索页面：

*   **哈希（`__hash__`）用于去重**：每个 `Result` 类型定义一个特殊的 `__hash__` 方法。此方法为每个结果的*内容*生成唯一的数字，而不仅仅是对象本身。如果来自不同引擎的两个结果具有相同的哈希（意味着它们指向本质上相同的内容），它们被视为重复项。

    ```python
    # 简化自 searx/result_types/_base.py（MainResult.__hash__）
    class MainResult(Result):
        # ... 其他字段和方法 ...
        def __hash__(self) -> int:
            if not self.parsed_url:
                raise ValueError("字段 'parsed_url' 中缺少值")

            url = self.parsed_url
            # 基于模板、域、路径和图像源创建哈希
            return hash(
                f"{self.template}"
                + f"|{url.netloc}|{url.path}|{url.params}|{url.query}|{url.fragment}"
                + f"|{self.img_src}"
            )
    ```
    -   这个 `__hash__` 方法允许 SearXNG 快速识别两个 `MainResult` 对象（即使来自不同的引擎）是否表示相同的网络链接。
    -   `Answer` 对象有自己的 `__hash__` 方法，通常基于 `answer` 文本本身。

*   **合并重复项（`merge_two_main_results`）**：当 `ResultContainer` 找到两个具有相同哈希的 `MainResult` 项时，它不只是丢弃一个。它合并它们，优先选择更丰富的内容。

    ```python
    # 简化自 searx/results.py
    def merge_two_main_results(origin: MainResult | LegacyResult, other: MainResult | LegacyResult):
        """将 ``other`` 的值合并到 ``origin`` 中。"""

        # 使用文本更多的内容
        if len(other.content or "") > len(origin.content or ""):
            origin.content = other.content

        # 使用文本更多的标题
        if len(other.title or "") > len(origin.title or ""):
            origin.title = other.title

        # 将找到 'other' 结果的引擎添加到 'origin' 结果的列表中
        origin.engines.add(other.engine or "")

        # 如果可用，优先使用 HTTPS URL
        if origin.parsed_url and not origin.parsed_url.scheme.endswith("s"):
            if other.parsed_url and other.parsed_url.scheme.endswith("s"):
                origin.parsed_url = origin.parsed_url._replace(scheme=other.parsed_url.scheme)
                origin.url = origin.parsed_url.geturl()
    ```
    -   这确保最终显示的结果具有最佳的标题、描述，并且还列出了所有为其做出贡献的引擎。

*   **评分（`calculate_score`）**：合并结果后，它们会被赋予"分数"。此分数有助于确定它们在页面上的最终顺序。诸如结果在引擎中的原始位置（较早的位置通常意味着更高的相关性）和引擎的配置"权重"等因素会影响分数。

    ```python
    # 简化自 searx/results.py
    import searx.engines # 获取引擎权重
    
    def calculate_score(
        result: MainResult | LegacyResult,
        priority: MainResult.PriorityType,
    ) -> float:
        weight = 1.0
        # 合并找到此结果的引擎的权重
        for result_engine in result['engines']:
            engine_obj = searx.engines.engines.get(result_engine)
            if engine_obj and hasattr(engine_obj, 'weight'):
                weight *= float(engine_obj.weight)
    
        weight *= len(result['positions']) # 更多引擎找到它意味着更高的权重
        score = 0
    
        for position in result['positions']: # 来自引擎的原始位置
            if priority == 'low':
                continue
            if priority == 'high':
                score += weight
            else:
                score += weight / position # 较低的位置编号 = 较高的分数
        return score
    ```
    -   `result['engines']`：此集合包含找到此特定合并结果的所有引擎名称。
    -   `result['positions']`：这是来自每个贡献引擎的结果的*原始*位置列表。
    -   `weight / position`：一种常见的排名技术，其中找到较高位置（较低的 `position` 编号）的结果获得更好的分数。

### 内部实现演练

让我们追踪 SearXNG 内部如何收集和聚合结果。

1.  **引擎产生结果**：一个**[EngineProcessor](01_search_orchestration__processor__.md)**完成对外部提供商的请求，并使用其相应**[引擎](04_engines__.md)**的 `response` 方法，将原始数据转换为 SearXNG `Result` 对象列表（例如，`MainResult`、`Answer`）。
2.  **结果被添加到 `ResultContainer`**：`EngineProcessor` 调用 `result_container.extend(engine_name, search_results)` 将其发现添加到中央 `ResultContainer`。
3.  **`ResultContainer.extend()` 处理每个结果**：
    *   它遍历结果列表。
    *   对于每个结果，它首先设置其 `engine` 字段并调用 `normalize_result_fields()` 来清理 URL 和文本。
    *   然后它检查结果的*类型*：
        *   如果它是 `Answer` 或 `BaseAnswer` 子类（如 `WeatherAnswer`），它将其添加到 `answers` 集合中，该集合自动处理答案的去重。
        *   如果它是 `MainResult`，它会尝试使用其哈希将其与 `main_results_map` 中的现有主要结果合并。
        *   如果它是 `LegacyResult`（可能包含建议、更正或信息框），它会将其分派到 `ResultContainer` 中的适当列表/集合。
4.  **所有引擎完成**：一旦来自**[搜索编排](01_search_orchestration__processor__.md)**的所有并发搜索请求都返回了结果或超时，就会调用 `ResultContainer.close()` 方法。
5.  **评分和最终排序**：
    *   `close()` 使用 `calculate_score` 为 `main_results_map` 中的所有 `MainResult` 对象计算 `score`。
    *   然后调用 `get_ordered_results()` 方法来检索用于显示的最终主要结果列表。此方法按计算的分数对结果进行排序，并应用分组逻辑（例如，确保类别或模板的混合）以防止一种类型的结果主导顶部。
6.  **显示**：排序的 `MainResult` 对象，以及收集的 `answers`、`infoboxes`、`suggestions` 和 `corrections`，被传递到模板系统以渲染最终的 HTML 搜索结果页面。

以下是搜索查询的简化事件序列：

```mermaid
sequenceDiagram
    participant EngineProcessor as 引擎处理器
    participant EngineModule as 引擎模块
    participant ResultContainer as 结果容器
    participant DisplaySystem as 显示系统

    EngineProcessor->>EngineModule: 1. 请求外部引擎
    EngineModule-->>EngineProcessor: 2. 来自外部引擎的原始数据
    EngineProcessor->>EngineModule: 3. 调用 EngineModule.response()
    Note over EngineModule: 创建类型化的 Result 对象（MainResult、Answer）
    EngineModule-->>EngineProcessor: 4. 返回 Result 对象列表
    EngineProcessor->>ResultContainer: 5. extend(engine_name, [Result1, Result2])
    Note over ResultContainer: 处理 Result1（例如，添加到 answers）
    Note over ResultContainer: 处理 Result2（例如，合并到 main_results_map）
    loop 对于每个引擎处理器
        ... 重复步骤 1-5 ...
    end
    ResultContainer->>ResultContainer: 6. close()
    Note over ResultContainer: 为所有 MainResults 计算分数
    ResultContainer->>ResultContainer: 7. get_ordered_results()
    Note over ResultContainer: 按分数/类别对 MainResults 进行排序和分组
    ResultContainer-->>DisplaySystem: 8. 返回聚合结果
    DisplaySystem-->>User: 9. 显示统一的搜索页面
```

### 代码

让我们看看实现这些概念的关键代码部分。

#### 1. 基础 `Result` 和 `MainResult` 类（`searx/result_types/_base.py`）

这些类定义了核心结构以及如何规范化结果。

```python
# 简化自 searx/result_types/_base.py

def _normalize_url_fields(result: "Result | LegacyResult"):
    # 确保 URL 正确解析和格式化
    if result.url and not result.parsed_url:
        result.parsed_url = urllib.parse.urlparse(result.url)
        # ... 确保方案（http/https）和清理路径的逻辑
    if result.parsed_url:
        result.url = result.parsed_url.geturl()

def _normalize_text_fields(result: "MainResult | LegacyResult"):
    # 清理标题和内容文本
    if result.title:
        result.title = WHITESPACE_REGEX.sub(" ", result.title).strip()
    if result.content:
        result.content = WHITESPACE_REGEX.sub(" ", result.content).strip()
    if result.content == result.title:
        result.content = "" # 如果内容等于标题，避免重复文本

class Result(msgspec.Struct, kw_only=True):
    # ... url、engine、parsed_url 等字段 ...

    def normalize_result_fields(self):
        # 调用 URL 规范化的辅助函数
        _normalize_url_fields(self)

    def __hash__(self) -> int:
        # 默认哈希，设计为由子类覆盖
        return id(self)

class MainResult(Result):
    # ... title、content、img_src 等字段 ...

    def __hash__(self) -> int:
        # MainResult 的自定义哈希用于去重
        if not self.parsed_url:
            raise ValueError(f"字段 'parsed_url' 中缺少值：{self}")
        url = self.parsed_url
        # 基于 URL 组件和 img_src 的哈希以识别重复链接
        return hash(
            f"{self.template}|{url.netloc}|{url.path}|{url.params}|{url.query}|{url.fragment}"
            + f"|{self.img_src}"
        )

    def normalize_result_fields(self):
        super().normalize_result_fields() # 调用父类的规范化
        _normalize_text_fields(self)      # 规范化文本字段
        # ... 和日期字段
        if self.engine:
            self.engines.add(self.engine) # 将引擎添加到查找器集合
```
-   `_normalize_url_fields` 和 `_normalize_text_fields`：这些是清理和标准化结果对象内数据的辅助函数。
-   `Result.__hash__`：基础 `Result` 有一个通用哈希，但 `MainResult`（和其他特定类型）覆盖它以提供基于*内容*而不仅仅是对象标识的哈希至关重要。这使得基于内容的去重成为可能。
-   `MainResult.normalize_result_fields`：此方法确保在引擎创建 `MainResult` 后，其 URL 和文本内容格式一致。

#### 2. 答案类型（`searx/result_types/answer.py`）

此文件定义了即时答案的结构化类型。

```python
# 简化自 searx/result_types/answer.py
from searx import weather
from ._base import Result

class BaseAnswer(Result, kw_only=True):
    # 答案的抽象基类
    pass

class AnswerSet:
    # BaseAnswer 项的聚合器，处理去重
    def __init__(self):
        self._answerlist = []

    def add(self, answer: BaseAnswer) -> None:
        a_hash = hash(answer) # 使用答案的哈希进行去重
        for i in self._answerlist:
            if hash(i) == a_hash:
                return # 如果已存在，不添加
        self._answerlist.append(answer)

class Answer(BaseAnswer, kw_only=True):
    template: str = "answer/legacy.html"
    answer: str # 答案的核心文本

    def __hash__(self):
        return hash(self.answer) # 基于其文本内容哈希 Answer

class WeatherAnswer(BaseAnswer, kw_only=True):
    template: str = "answer/weather.html"
    current: "WeatherAnswer.Item" # 当前天气信息
    forecasts: "list[WeatherAnswer.Item]" = [] # 未来预报
    service: str = "" # 天气数据来源

    class Item(msgspec.Struct, kw_only=True):
        location: weather.GeoLocation
        temperature: weather.Temperature
        condition: weather.WeatherConditionType
        # ... 其他天气详细信息
```
-   `AnswerSet`：此类在 `ResultContainer` 中使用，通过比较它们的 `hash` 值自动去重答案。
-   `Answer.__hash__`：通用 `Answer` 的哈希只是其 `answer` 文本的哈希。这意味着如果两个引擎提供完全相同的答案文本，`AnswerSet` 会将它们视为重复项。

#### 3. `ResultContainer`（`searx/results.py`）

这是收集和聚合魔法发生的地方。

```python
# 简化自 searx/results.py
import typing as t
from threading import RLock
from searx.result_types import Result, LegacyResult, MainResult
from searx.result_types.answer import AnswerSet, BaseAnswer

class ResultContainer:
    # ... 如前所示的 __init__ ...

    def extend(
        self, engine_name: str | None, results: list[Result | LegacyResult]
    ):
        if self._closed: # 如果容器已经最终确定，不添加
            log.debug("容器已关闭，忽略结果")
            return

        for result in list(results):
            if isinstance(result, Result): # 检查它是否是现代类型化结果
                result.engine = result.engine or engine_name
                result.normalize_result_fields()
                # self.on_result(result) 允许插件过滤/修改
                if isinstance(result, BaseAnswer):
                    self.answers.add(result) # 添加到 AnswerSet 进行去重
                elif isinstance(result, MainResult):
                    # 对于 MainResult，尝试合并它
                    self._merge_main_result(result, main_count)
                    main_count += 1
                else:
                    raise NotImplementedError(f"类型 {result} 没有处理程序")
            else:
                # 处理 LegacyResult（旧的基于字典的结果）
                result = LegacyResult(result)
                result.normalize_result_fields()
                if "suggestion" in result:
                    self.suggestions.add(result["suggestion"])
                elif "answer" in result:
                    self.answers.add(result) # 旧答案添加到 AnswerSet
                # ... 处理其他旧类型，如 correction、infobox
                else: # 如果没有其他类型，默认合并为主要结果
                    self._merge_main_result(result, main_count)
                    main_count += 1

    def _merge_main_result(self, result: MainResult | LegacyResult, position: int):
        result_hash = hash(result) # 获取基于内容的哈希

        with self._lock: # 保护共享数据免受并发访问
            merged = self.main_results_map.get(result_hash)
            if not merged:
                # 如果未找到重复项，添加为新结果
                result.positions = [position]
                self.main_results_map[result_hash] = result
                return

            # 如果找到重复项，将其与现有的合并
            merge_two_main_results(merged, result)
            merged.positions.append(position) # 添加新位置

    def close(self):
        self._closed = True
        for result in self.main_results_map.values():
            result.score = calculate_score(result, result.priority)
            # ... 更新指标 ...

    def get_ordered_results(self) -> list[MainResult | LegacyResult]:
        if not self._closed:
            log.error("在 close 之前调用 ResultContainer.get_ordered_results")
            return []
        if self._main_results_sorted:
            return self._main_results_sorted # 返回缓存的排序列表

        # 按分数排序结果（最高分数优先）
        results = sorted(self.main_results_map.values(), key=lambda x: x.score, reverse=True)

        # 应用分组逻辑以获得更好的显示（例如，混合类别）
        # ... 按类别/模板分组的复杂逻辑 ...

        self._main_results_sorted = gresults # 缓存排序列表
        return self._main_results_sorted
```
-   `extend()`：这是添加结果的核心方法。它旨在区分类型化的 `Result` 对象和 `LegacyResult` 字典，将它们分派到正确的内部列表/集合并应用 `normalize_result_fields`。
-   `_merge_main_result()`：此私有方法对去重至关重要。它使用 `hash(result)` 检查 `main_results_map` 是否有现有匹配。如果找到，`merge_two_main_results` 将它们组合；否则，添加新结果。
-   `close()`：此方法最终确定容器，为所有主要结果计算分数，并为排序做好准备。
-   `get_ordered_results()`：此方法返回最终的、准备显示的主要结果列表，按分数排序，并可能分组以获得最佳用户体验。

### 结论

结果类型与聚合是将不同搜索结果的混乱带入秩序的无名英雄。通过定义清晰的类型、提供用于收集的中央 `ResultContainer`，以及实现用于去重、合并和评分的智能逻辑，SearXNG 确保用户获得统一、全面且组织良好的搜索体验。这个系统使 SearXNG 的元搜索功能真正强大且用户友好。

接下来，我们将==探索**[插件](06_plugins__.md)**如何扩展 SearXNG 的功能，甚至与这些结果类型交互==

[下一章：插件](06_plugins_.md)

