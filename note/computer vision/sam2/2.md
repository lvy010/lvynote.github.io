# ç¬¬äºŒç« ï¼šSAM2è§†é¢‘é¢„æµ‹å™¨ï¼ˆè§†é¢‘è¿½è¸ªAPIï¼‰

æ¬¢è¿å›æ¥

åœ¨[ç¬¬ä¸€ç« ï¼šSAM2å›¾åƒé¢„æµ‹å™¨ï¼ˆå›¾åƒæ¨ç†APIï¼‰](01_sam2imagepredictor__image_inference_api_.md)ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†`SAM2ImagePredictor`å¦‚ä½•å¸®åŠ©æˆ‘ä»¬ç²¾ç¡®åœ°ä»*å•å¼ *å›¾ç‰‡ä¸­åˆ†å‰²å¯¹è±¡ã€‚å®ƒå°±åƒæ˜¯ä¸ºé™æ€å›¾åƒé…å¤‡äº†ä¸€ä½è¶…çº§æ™ºèƒ½çš„ä¿®å›¾å¸ˆã€‚

ä½†å¦‚æœä½ çš„ç›®æ ‡å¯¹è±¡ä¸æ˜¯é™æ­¢çš„å‘¢ï¼Ÿå¦‚æœä½ çš„å® ç‰©çŒ«æ­£åœ¨è§†é¢‘ä¸­å¥”è·‘ï¼Œè€Œä½ å¸Œæœ›æ¯ä¸€å¸§éƒ½èƒ½çªå‡ºæ˜¾ç¤ºå®ƒï¼Œæ‰‹åŠ¨åœ¨æ•°ç™¾ç”šè‡³æ•°åƒå¸§ä¸­ç‚¹å‡»çŒ«å’ªç®€ç›´æ˜¯å™©æ¢¦ï¼

è¿™æ—¶ï¼Œæˆ‘ä»¬çš„ä¸‹ä¸€ä¸ªå¼ºå¤§å·¥å…·`SAM2VideoPredictor`å°±æ´¾ä¸Šç”¨åœºäº†ã€‚ä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆSAM-2çš„ä¸“å±**è§†é¢‘è¿½è¸ªå¯¼æ¼”**ã€‚å®ƒä¸ä»…èƒ½å¤Ÿç¼–è¾‘å•å¼ å›¾åƒï¼Œè¿˜èƒ½æ™ºèƒ½åœ°==è¿½è¸ªå¹¶åˆ†å‰²==è§†é¢‘ä¸­ç§»åŠ¨çš„å¯¹è±¡ã€‚

### è§£å†³çš„é—®é¢˜

`SAM2VideoPredictor`çš„æ ¸å¿ƒä»»åŠ¡æ˜¯**è§†é¢‘å¯¹è±¡åˆ†å‰²ï¼ˆVOSï¼‰**ï¼Œå³åœ¨è§†é¢‘çš„æ‰€æœ‰å¸§ä¸­æ‰¾åˆ°å¹¶å‹¾å‹’å‡ºç‰¹å®šå¯¹è±¡ã€‚

å‡è®¾æœ‰ä¸€æ®µç¹å¿™è¡—é“çš„è§†é¢‘ï¼Œ==æƒ³ä»çº¢è½¦å‡ºç°çš„é‚£ä¸€åˆ»å¼€å§‹è¿½è¸ªï¼Œç›´åˆ°å®ƒé©¶å‡ºç”»é¢==ã€‚è¿™éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºï¼š

*   **å¯¹è±¡ä¼šç§»åŠ¨å’Œå˜å½¢**ï¼šè½¦è¾†å¯èƒ½è½¬å¼¯ã€é è¿‘æˆ–è¢«éƒ¨åˆ†é®æŒ¡ã€‚
*   **å…‰ç…§å˜åŒ–**ï¼šé˜´å½±ã€é˜³å…‰æˆ–å¤œæ™šä¼šæ”¹å˜å…¶å¤–è§‚ã€‚
*   **é®æŒ¡é—®é¢˜**ï¼šå…¶ä»–è½¦è¾†æˆ–ç‰©ä½“å¯èƒ½æš‚æ—¶æŒ¡ä½çº¢è½¦ã€‚

`SAM2VideoPredictor`é€šè¿‡è®°å¿†å¯¹è±¡çš„å¤–è§‚ã€é¢„æµ‹å…¶ä½ç½®ï¼Œå¹¶æ ¹æ®æ–°å¸§è°ƒæ•´é¢„æµ‹æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚å®ƒå°±åƒä¸€ä½ä¸“ä¸šçš„è§†é¢‘ç¼–è¾‘ï¼Œèƒ½å¤Ÿ==æ™ºèƒ½åœ°è·Ÿéš==å¹¶é«˜äº®å¯¹è±¡ï¼Œå³ä½¿å®ƒæš‚æ—¶æ¶ˆå¤±åˆå‡ºç°ï¼

### è§†é¢‘è¿½è¸ªå¯¼æ¼”

è®©æˆ‘ä»¬æ‹†è§£`SAM2VideoPredictor`å¦‚ä½•å®Œæˆè¿™é¡¹å¤æ‚ä»»åŠ¡ï¼Œå°±åƒå¯¼æ¼”æŒ‡æŒ¥ä¸€éƒ¨ç”µå½±ï¼š

1.  **åœºæ™¯è®¾ç½®ï¼ˆ`inference_state`ï¼‰**ï¼š  
    åœ¨å¼€å§‹è¿½è¸ªä¹‹å‰ï¼Œå¯¼æ¼”éœ€è¦ä¸€ä¸ªâ€œé¡¹ç›®æ–‡ä»¶â€ã€‚`inference_state`æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„å­˜å‚¨åŒºï¼Œè®°å½•è§†é¢‘å’Œå¾…åˆ†å‰²å¯¹è±¡çš„æ‰€æœ‰é‡è¦ä¿¡æ¯ï¼ŒåŒ…æ‹¬è§†é¢‘å¸§ã€åˆå§‹æç¤ºï¼ˆå¦‚ç‚¹å‡»çº¢è½¦ï¼‰ã€å†å²é¢„æµ‹ä»¥åŠæè¿°å¯¹è±¡éšæ—¶é—´å˜åŒ–çš„â€œè®°å¿†ç‰¹å¾â€ã€‚éšç€è¿½è¸ªçš„è¿›è¡Œï¼Œè¿™ä¸ªçŠ¶æ€ä¼šä¸æ–­æ›´æ–°ã€‚

2.  **åˆå§‹é€‰è§’ï¼ˆæ·»åŠ ç‚¹å‡»/æ©è†œï¼‰**ï¼š  
    ä½ å‘Šè¯‰å¯¼æ¼”è¦è¿½è¸ªå“ªä¸ªå¯¹è±¡ï¼Œé€šå¸¸é€šè¿‡åœ¨ç¬¬ä¸€å¸§ç‚¹å‡»çº¢è½¦æˆ–ç»˜åˆ¶ä¸€ä¸ªç²—ç•¥çš„æ©è†œæ¥å®Œæˆã€‚å¯¼æ¼”ä¼šå°†è¿™äº›ä¿¡æ¯è®°å½•åœ¨`inference_state`ä¸­ã€‚

3.  **æ•…äº‹æ¨è¿›ï¼ˆè§†é¢‘è¿½è¸ªï¼‰**ï¼š  
    ä¸€æ—¦æœ‰äº†åˆå§‹æç¤ºï¼Œå¯¼æ¼”å°±ä¼šæ¥ç®¡å·¥ä½œã€‚å®ƒåˆ©ç”¨`inference_state`ä¸­çš„ä¿¡æ¯é¢„æµ‹å¯¹è±¡åœ¨*ä¸‹ä¸€å¸§*çš„ä½ç½®å’Œå½¢çŠ¶ï¼Œæ›´æ–°è®°å¿†ï¼Œå¹¶ç»§ç»­å¤„ç†åç»­å¸§ã€‚å®ƒç”šè‡³å¯ä»¥*åå‘*è¿½è¸ªæ—¶é—´ï¼Œè¿™ä¸ªè¿‡ç¨‹ç§°ä¸º==åˆ†å‰²ä¼ æ’­==

ç®€è€Œè¨€ä¹‹ï¼Œ`SAM2VideoPredictor`æ ¹æ®åˆå§‹æŒ‡å¼•ï¼Œè‡ªåŠ¨åœ¨æ¯ä¸€å¸§ä¸­æ‰¾åˆ°ç›®æ ‡å¯¹è±¡ï¼Œä½¿è§†é¢‘åˆ†å‰²å˜å¾—é«˜æ•ˆå®ç”¨ã€‚

### å¦‚ä½•ä½¿ç”¨SAM2VideoPredictor

è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç®€å•ç¤ºä¾‹æ¥å­¦ä¹ å¦‚ä½•è¿½è¸ªè§†é¢‘ä¸­çš„å¯¹è±¡

**æ­¥éª¤1ï¼šåŠ è½½è§†é¢‘é¢„æµ‹å™¨**  
ä¸å›¾åƒé¢„æµ‹å™¨ç±»ä¼¼ï¼Œæˆ‘ä»¬éœ€è¦å‡†å¤‡`SAM2VideoPredictor`ï¼Œè¿™åŒ…æ‹¬åŠ è½½æ ¸å¿ƒSAM-2æ¨¡å‹å¹¶å°†å…¶å°è£…ä¸ºè§†é¢‘é¢„æµ‹å·¥å…·ã€‚

```python
from sam2.build_sam import build_sam2_video_predictor_hf
import torch

# æŒ‡å®šè®¾å¤‡ï¼ˆé€šå¸¸ä¸ºNVIDIA GPUçš„"cuda"ï¼‰
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 1. åŠ è½½ä¸“ä¸ºè§†é¢‘è¿½è¸ªè®­ç»ƒçš„SAM-2æ¨¡å‹
# "facebook/sam2-hiera-base-plus"æ˜¯ä¸€ä¸ªç¤ºä¾‹æ¨¡å‹IDã€‚
predictor = build_sam2_video_predictor_hf(
    model_id="facebook/sam2-hiera-base-plus",
    device=device
)
```
*è¯´æ˜*ï¼šæˆ‘ä»¬ä½¿ç”¨`build_sam2_video_predictor_hf`ï¼ˆç±»ä¼¼äºç¬¬ä¸€ç« çš„`build_sam2_hf`ï¼‰åŠ è½½å¿…è¦ç»„ä»¶ã€‚ç°åœ¨ï¼Œ`predictor`å°±æ˜¯æˆ‘ä»¬çš„è§†é¢‘è¿½è¸ªå¯¼æ¼”ï¼Œå‡†å¤‡å°±ç»ª

**æ­¥éª¤2ï¼šåˆå§‹åŒ–è§†é¢‘è¿½è¸ªé¡¹ç›®ï¼ˆ`inference_state`ï¼‰**  
æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä¸ºå¯¼æ¼”æä¾›è§†é¢‘ã€‚é¢„æµ‹å™¨ä¼šåŠ è½½å¸§å¹¶è®¾ç½®â€œé¡¹ç›®æ–‡ä»¶â€ï¼ˆ`inference_state`ï¼‰ã€‚

```python
import os
import numpy as np
# å‡è®¾ä½ æœ‰ä¸€ä¸ªåä¸º'my_video_frames'çš„æ–‡ä»¶å¤¹ï¼ŒåŒ…å«JPEGå›¾åƒ
# ä¾‹å¦‚ï¼šmy_video_frames/00000.jpg, my_video_frames/00001.jpgç­‰
video_dir = "my_video_frames" # æ›¿æ¢ä¸ºä½ çš„è§†é¢‘å¸§è·¯å¾„

# ä¸ºæ­¤ç¤ºä¾‹åˆ›å»ºè™šæ‹Ÿè§†é¢‘ç›®å½•å’Œå¸§
os.makedirs(video_dir, exist_ok=True)
dummy_image = np.zeros((256, 256, 3), dtype=np.uint8)
from PIL import Image
Image.fromarray(dummy_image).save(os.path.join(video_dir, "00000.jpg"))
# æ·»åŠ å¦ä¸€å¸§ç”¨äºè¿½è¸ª
Image.fromarray(dummy_image).save(os.path.join(video_dir, "00001.jpg"))

# ç”¨è§†é¢‘å¸§åˆå§‹åŒ–è¿½è¸ªçŠ¶æ€
inference_state = predictor.init_state(video_path=video_dir)

print(f"è§†é¢‘å¸§æ•°ï¼š{inference_state['num_frames']}")
print(f"è§†é¢‘åˆ†è¾¨ç‡ï¼š{inference_state['video_height']}x{inference_state['video_width']}")
```
*è¯´æ˜*ï¼š`init_state()`å‡†å¤‡`inference_state`ï¼ŒåŠ è½½è§†é¢‘å¸§ï¼ˆæˆ–å…¶è·¯å¾„ï¼‰ï¼Œç¡®å®šè§†é¢‘å°ºå¯¸ï¼Œå¹¶==è®¾ç½®å­˜å‚¨å¯¹è±¡æ•°æ®å’Œè¿½è¸ªç»“æœçš„å†…éƒ¨å­—å…¸==

é€šè¿‡å¤„ç†ç¬¬ä¸€å¸§çš„å›¾åƒç‰¹å¾è¿›è¡Œâ€œé¢„çƒ­â€ï¼ŒåŠ é€Ÿåç»­æ­¥éª¤

**æ­¥éª¤3ï¼šä¸ºå¯¹è±¡æ·»åŠ åˆå§‹æç¤ºï¼ˆç‚¹å‡»/æ©è†œï¼‰**  
ç°åœ¨ï¼Œæˆ‘ä»¬==å‘Šè¯‰å¯¼æ¼”*è¿½è¸ªå“ªä¸ªå¯¹è±¡*==ã€‚é€šå¸¸åœ¨ç¬¬ä¸€å¸§ï¼ˆç´¢å¼•0ï¼‰ç‚¹å‡»æˆ–ç»˜åˆ¶æ©è†œï¼Œå¹¶ä¸ºå¯¹è±¡åˆ†é…å”¯ä¸€IDï¼ˆå¦‚1ï¼‰

```python
# å‡è®¾æˆ‘ä»¬åœ¨å¸§0çš„(x=100, y=150)å¤„ç‚¹å‡»å¯¹è±¡
ann_frame_idx = 0
ann_obj_id = 1 # å¾…è¿½è¸ªå¯¹è±¡çš„å”¯ä¸€ID
points = np.array([[100, 150]], dtype=np.float32) # ç‚¹å‡»åæ ‡
labels = np.array([1], np.int32) # æ ‡ç­¾1è¡¨ç¤ºå‰æ™¯ç‚¹

# å°†æ­¤æç¤ºæ·»åŠ åˆ°é¢„æµ‹å™¨
frame_idx_out, obj_ids_out, masks_out = predictor.add_new_points_or_box(
    inference_state=inference_state,
    frame_idx=ann_frame_idx,
    obj_id=ann_obj_id,
    points=points,
    labels=labels,
)

print(f"å¸§{frame_idx_out}çš„æ©è†œï¼ˆå¯¹è±¡{obj_ids_out}ï¼‰å½¢çŠ¶ï¼š{masks_out.shape}")
```
*è¯´æ˜*ï¼š`add_new_points_or_box()`æ¥æ”¶ä½ çš„æç¤ºï¼ˆæ­¤å¤„ä¸ºç‚¹å‡»ï¼‰ï¼Œå¹¶å°†å…¶åº”ç”¨åˆ°æŒ‡å®šå¸§å’Œå¯¹è±¡ã€‚å†…éƒ¨è°ƒç”¨ç±»ä¼¼`SAM2ImagePredictor`çš„ç»„ä»¶ï¼Œåœ¨*å•å¸§*ä¸­åˆ†å‰²å¯¹è±¡ï¼Œç»“æœï¼ˆæ©è†œï¼‰å­˜å‚¨åœ¨`inference_state`ä¸­ï¼Œä½œä¸º==å¯¹è±¡1åœ¨å¸§0çš„èµ·ç‚¹==ã€‚

**æ­¥éª¤4ï¼šåœ¨è§†é¢‘ä¸­==ä¼ æ’­åˆ†å‰²==**  
æœ€åï¼Œæˆ‘ä»¬è®©å¯¼æ¼”å¼€å§‹è¿½è¸ªï¼`propagate_in_video`æ–¹æ³•ä¼šé€å¸§å¤„ç†æ•´ä¸ªè§†é¢‘ï¼Œåˆ©ç”¨è®°å¿†è·Ÿéšå¯¹è±¡ã€‚

```python
all_tracked_masks = {}

# 'propagate_in_video'æ˜¯ä¸€ä¸ªPythonç”Ÿæˆå™¨ï¼Œ
# é€å¸§ç”Ÿæˆå¤„ç†ç»“æœã€‚
for frame_idx, obj_ids, video_res_masks in predictor.propagate_in_video(inference_state):
    # 'video_res_masks'åŒ…å«å½“å‰å¸§æ‰€æœ‰è¿½è¸ªå¯¹è±¡çš„æ©è†œï¼Œ
    # å·²è°ƒæ•´ä¸ºåŸå§‹è§†é¢‘åˆ†è¾¨ç‡ã€‚
    # æˆ‘ä»¬å¯ä»¥å­˜å‚¨æˆ–æ˜¾ç¤ºè¿™äº›æ©è†œã€‚
    all_tracked_masks[frame_idx] = video_res_masks
    print(f"å·²å¤„ç†å¸§{frame_idx}ã€‚æ©è†œå½¢çŠ¶ï¼š{video_res_masks.shape}")

print(f"æˆåŠŸè¿½è¸ª{len(all_tracked_masks)}å¸§ã€‚")
# å¾ªç¯ç»“æŸåï¼Œ'all_tracked_masks'å°†åŒ…å«æ‰€æœ‰è¿½è¸ªå¸§çš„åˆ†å‰²å¯¹è±¡ã€‚
```
*è¯´æ˜*ï¼š`propagate_in_video()`éå†è§†é¢‘å¸§ã€‚å¯¹äºæ¯å¸§ï¼Œå®ƒåˆ©ç”¨ç´¯ç§¯çš„`inference_state`ï¼ˆåŒ…å«å¯¹è±¡å¤–è§‚å’Œè¿åŠ¨å†å²ï¼‰é¢„æµ‹å½“å‰å¸§çš„æ©è†œï¼Œæ›´æ–°`inference_state`å¹¶è¿”å›ç»“æœã€‚è¿™æ˜¯è§†é¢‘è¿½è¸ªçš„æ ¸å¿ƒã€‚

### æŠ€æœ¯

è®©æˆ‘ä»¬æ·±å…¥å¹•åï¼Œäº†è§£`SAM2VideoPredictor`çš„é­”æ³•ã€‚

#### ğŸ¢å·¥ä½œæµç¨‹
å°†`SAM2VideoPredictor`æƒ³è±¡æˆä¸€ä½ç»éªŒä¸°å¯Œçš„å¯¼æ¼”ï¼Œé…å¤‡æ™ºèƒ½åŠ©æ‰‹ï¼ˆ`inference_state`ï¼‰ã€‚

1.  **ä½ ï¼ˆç”¨æˆ·ï¼‰**å°†è§†é¢‘ï¼ˆJPEGå›¾åƒæ–‡ä»¶å¤¹ï¼‰äº¤ç»™å¯¼æ¼”ï¼ˆ`SAM2VideoPredictor`ï¼‰ã€‚
2.  å¯¼æ¼”è®©åŠ©æ‰‹ï¼ˆ`inference_state`ï¼‰å‡†å¤‡æ•´ä¸ªè§†é¢‘ã€‚åŠ©æ‰‹åŠ è½½æ‰€æœ‰å¸§ï¼Œå¹¶ä¸ºæ¯ä¸ªå¯¹è±¡å’Œå¸§åˆ›å»ºç©ºæ–‡ä»¶ï¼ŒåŒæ—¶ä»ç¬¬ä¸€å¸§æå–åˆå§‹â€œç²¾åâ€ï¼ˆ`image_features`ï¼‰ã€‚
3.  åœ¨åˆå§‹å¸§ï¼ˆå¦‚å¸§0ï¼‰ç‚¹å‡»ç›®æ ‡å¯¹è±¡ã€‚
4.  å¯¼æ¼”å¤„ç†æ­¤ç‚¹å‡»ï¼ˆç±»ä¼¼[SAM2ImagePredictor](01_sam2imagepredictor__image_inference_api_.md)çš„æ–¹å¼ï¼‰ï¼Œè·å–æ©è†œï¼Œå¹¶å°†å¯¹è±¡çš„ç¬¬ä¸€å¼ åˆ†å‰²å›¾åƒå­˜å…¥`inference_state`ï¼Œå½¢æˆâ€œåˆå§‹å¤–è§‚æ¡£æ¡ˆâ€ã€‚å¯¼æ¼”è¿˜ä½¿ç”¨[è®°å¿†ç¼–ç å™¨](07_memory_encoder_.md)è®¡ç®—å¹¶å­˜å‚¨æ­¤å¸§çš„â€œè®°å¿†ç‰¹å¾â€ã€‚
5.  ä½ å‘å‡ºæŒ‡ä»¤ï¼šâ€œåœ¨æ•´ä¸ªè§†é¢‘ä¸­è¿½è¸ªæ­¤å¯¹è±¡ï¼â€ï¼ˆ`propagate_in_video`ï¼‰ã€‚
6.  å¯¹äºåç»­æ¯å¸§ï¼š
    *   å¯¼æ¼”ä»`inference_state`è·å–å¯¹è±¡çš„æœ€æ–°â€œå¤–è§‚æ¡£æ¡ˆâ€å’Œâ€œè®°å¿†ç‰¹å¾â€ã€‚
    *   ç»“åˆå½“å‰å¸§å›¾åƒå’Œå¯¹è±¡å†å²ï¼ˆè®°å¿†ç‰¹å¾ï¼‰ï¼Œé¢„æµ‹å¯¹è±¡çš„å½“å‰ä½ç½®ã€‚æ­¤æ­¥éª¤åˆ©ç”¨å¼ºå¤§çš„[SAM2åŸºç¡€æ¨¡å‹](03_sam2base_model_.md)åŠå…¶[è®°å¿†æ³¨æ„åŠ›](08_memory_attention_.md)ç»„ä»¶ã€‚
    *   ä¼˜åŒ–é¢„æµ‹ï¼Œå¡«è¡¥å°å­”ï¼Œå¹¶å°†æ–°æ©è†œå’Œæ›´æ–°çš„â€œè®°å¿†ç‰¹å¾â€å­˜å›`inference_state`ã€‚
    *   å±•ç¤ºå½“å‰å¸§çš„åˆ†å‰²å¯¹è±¡ã€‚

è¿™ç§â€œé¢„æµ‹ã€æ›´æ–°è®°å¿†ã€ä¿å­˜ã€ç§»è‡³ä¸‹ä¸€å¸§â€çš„å¾ªç¯ï¼Œä½¿`SAM2VideoPredictor`èƒ½å¤Ÿç¨³å¥åœ°è¿½è¸ªè§†é¢‘ä¸­çš„å¯¹è±¡ã€‚

ä»¥ä¸‹æ˜¯ç®€åŒ–çš„å·¥ä½œæµç¨‹å›¾ï¼š

```mermaid
sequenceDiagram
    participant ç”¨æˆ·
    participant é¢„æµ‹å™¨ as SAM2VideoPredictor
    participant çŠ¶æ€ as inference_state
    participant æ¨¡å‹ as SAM2Base Model
    participant è®°å¿†ç¼–ç å™¨ as Memory Encoder

    ç”¨æˆ·->>é¢„æµ‹å™¨: init_state(video_path)
    é¢„æµ‹å™¨->>çŠ¶æ€: åŠ è½½è§†é¢‘å¸§ï¼Œåˆå§‹åŒ–å†…å­˜
    Note over çŠ¶æ€: å­˜å‚¨åŸå§‹è§†é¢‘å¸§å’Œ<br/>å¸§0çš„åˆå§‹å›¾åƒç‰¹å¾

    ç”¨æˆ·->>é¢„æµ‹å™¨: add_new_points_or_box(å¸§0, å¯¹è±¡1, ç‚¹å‡»)
    é¢„æµ‹å™¨->>æ¨¡å‹: åŸºäºç‚¹å‡»é¢„æµ‹å¸§0çš„æ©è†œ
    æ¨¡å‹-->>é¢„æµ‹å™¨: åŸå§‹æ©è†œ_å¸§0
    é¢„æµ‹å™¨->>è®°å¿†ç¼–ç å™¨: å°†åŸå§‹æ©è†œ_å¸§0ç¼–ç ä¸ºè®°å¿†ç‰¹å¾
    è®°å¿†ç¼–ç å™¨-->>é¢„æµ‹å™¨: è®°å¿†ç‰¹å¾_å¸§0
    é¢„æµ‹å™¨->>çŠ¶æ€: å­˜å‚¨è®°å¿†ç‰¹å¾_å¸§0å’Œæ©è†œ_å¸§0

    ç”¨æˆ·->>é¢„æµ‹å™¨: propagate_in_video()
    loop é€å¸§å¤„ç†ï¼ˆå¦‚å¸§1, 2, ...ï¼‰
        é¢„æµ‹å™¨->>çŠ¶æ€: è·å–å½“å‰å¸§å›¾åƒç‰¹å¾
        é¢„æµ‹å™¨->>çŠ¶æ€: è·å–è®°å¿†ç‰¹å¾_å¸§N-1
        é¢„æµ‹å™¨->>æ¨¡å‹: ç»“åˆå½“å‰å›¾åƒå’Œè®°å¿†ç‰¹å¾è¿½è¸ªå¯¹è±¡
        æ¨¡å‹-->>é¢„æµ‹å™¨: æ–°æ©è†œ_å¸§N, æ–°å¯¹è±¡è¯„åˆ†_N
        é¢„æµ‹å™¨->>è®°å¿†ç¼–ç å™¨: æ›´æ–°æ–°æ©è†œ_å¸§Nçš„è®°å¿†ç‰¹å¾
        è®°å¿†ç¼–ç å™¨-->>é¢„æµ‹å™¨: è®°å¿†ç‰¹å¾_å¸§N
        é¢„æµ‹å™¨->>çŠ¶æ€: å­˜å‚¨æ–°æ©è†œ_å¸§Nå’Œè®°å¿†ç‰¹å¾_å¸§N
        é¢„æµ‹å™¨-->>ç”¨æˆ·: (å¸§N, å¯¹è±¡ID, æ©è†œ_å¸§N)
    end
```

#### å…³é”®ä»£ç 

![image-20251018111239341](image-20251018111239341.png)

![image-20251018111331223](image-20251018111331223.png)

è®©æˆ‘ä»¬çœ‹çœ‹`sam2/sam2_video_predictor.py`ä¸­å¦‚ä½•å®ç°è¿™äº›æ­¥éª¤ã€‚

1.  **åˆå§‹åŒ–ï¼ˆ`init_state`ï¼‰**  
    
    ```python
    def init_state(self, video_path, **kwargs):
        images, video_height, video_width = load_video_frames(
            video_path=video_path, image_size=self.image_size, **kwargs
        )
        
        inference_state = {
            "images": images,  # å­˜å‚¨æ‰€æœ‰è§†é¢‘å¸§
            "num_frames": len(images),
            "video_height": video_height,
            "video_width": video_width,
            "device": self.device,
            "point_inputs_per_obj": {},  # æ¯å¸§å¯¹è±¡çš„ç‚¹å‡»è¾“å…¥
            "mask_inputs_per_obj": {},    # æ¯å¸§å¯¹è±¡çš„æ©è†œè¾“å…¥
            "output_dict_per_obj": {},    # è¿½è¸ªç»“æœï¼ˆæ©è†œã€è®°å¿†ç‰¹å¾ï¼‰
            "obj_id_to_idx": OrderedDict(),  # å¯¹è±¡IDåˆ°å†…éƒ¨ç´¢å¼•çš„æ˜ å°„
            "obj_idx_to_id": OrderedDict(),
            "obj_ids": []
        }
        
        # é¢„çƒ­ç¬¬ä¸€å¸§çš„å›¾åƒç¼–ç å™¨
        self._get_image_feature(inference_state, frame_idx=0, batch_size=1)
        return inference_state
    ```
    *è¯´æ˜*ï¼š`init_state`è®¾ç½®`inference_state`å­—å…¸ï¼ŒåŠ è½½è§†é¢‘å¸§ï¼Œå­˜å‚¨åŸå§‹å°ºå¯¸ï¼Œå¹¶åˆå§‹åŒ–å¯¹è±¡æ•°æ®å’Œè¿½è¸ªç»“æœçš„å­˜å‚¨åŒºã€‚å®ƒè¿˜é¢„å¤„ç†ç¬¬ä¸€å¸§ä»¥ç¡®ä¿æ¨¡å‹å°±ç»ªã€‚
    
2.  **æ·»åŠ åˆå§‹æç¤ºï¼ˆ`add_new_points_or_box`ï¼‰**  
    
    ```python
    def add_new_points_or_box(self, inference_state, frame_idx, obj_id, points=None, labels=None, **kwargs):
        obj_idx = self._obj_id_to_idx(inference_state, obj_id)  # å¯¹è±¡IDæ˜ å°„
        
        # å­˜å‚¨ç‚¹å‡»è¾“å…¥
        inference_state["point_inputs_per_obj"][obj_idx][frame_idx] = concat_points(
            inference_state["point_inputs_per_obj"][obj_idx].get(frame_idx, None), points, labels
        )
    
        # è¿è¡Œå•å¸§æ¨ç†ï¼ˆç±»ä¼¼SAM2ImagePredictorï¼‰
        current_out, _ = self._run_single_frame_inference(
            inference_state=inference_state,
            output_dict=inference_state["output_dict_per_obj"][obj_idx],
            frame_idx=frame_idx,
            batch_size=1,
            is_init_cond_frame=True,  # æ ‡è®°ä¸ºåˆå§‹è¾“å…¥å¸§
            point_inputs=inference_state["point_inputs_per_obj"][obj_idx][frame_idx],
            mask_inputs=None,
            reverse=False,
            run_mem_encoder=False,  # è®°å¿†ç¼–ç å™¨ç¨åè¿è¡Œ
            prev_sam_mask_logits=None,
        )
        
        # ä¸´æ—¶å­˜å‚¨å½“å‰è¾“å‡ºæ©è†œ
        inference_state["temp_output_dict_per_obj"][obj_idx]["cond_frame_outputs"][frame_idx] = current_out
    
        # è¿”å›è°ƒæ•´åˆ°åŸå§‹è§†é¢‘åˆ†è¾¨ç‡çš„æ©è†œ
        consolidated_out = self._consolidate_temp_output_across_obj(inference_state, frame_idx, is_cond=True)
        _, video_res_masks = self._get_orig_video_res_output(inference_state, consolidated_out["pred_masks_video_res"])
        return frame_idx, inference_state["obj_ids"], video_res_masks
    ```
    *è¯´æ˜*ï¼šæ­¤æ–¹æ³•å°†å¯¹è±¡IDæ˜ å°„åˆ°å†…éƒ¨ç´¢å¼•ï¼Œå­˜å‚¨ç‚¹å‡»æ•°æ®ï¼Œå¹¶è°ƒç”¨`_run_single_frame_inference`ç”Ÿæˆå•å¸§æ©è†œã€‚ç»“æœæ©è†œä¸´æ—¶å­˜å…¥`inference_state`ï¼Œå¹¶è¿”å›è°ƒæ•´åçš„æ©è†œã€‚
    
3.  **ä¼ æ’­åˆ†å‰²ï¼ˆ`propagate_in_video`ï¼‰**  
    ```python
    def propagate_in_video(self, inference_state, start_frame_idx=None, **kwargs):
        self.propagate_in_video_preflight(inference_state)  # é¢„å¤„ç†åˆå§‹è¾“å…¥
        
        for frame_idx in processing_order:  # æŒ‰é¡ºåºå¤„ç†æ¯å¸§
            pred_masks_per_obj = []
            for obj_idx in range(batch_size):
                if frame_idx in obj_output_dict["cond_frame_outputs"]:
                    current_out = obj_output_dict["cond_frame_outputs"][frame_idx]
                else:
                    # è¿è¡Œè¿½è¸ªæ¨ç†
                    current_out, pred_masks = self._run_single_frame_inference(
                        inference_state=inference_state,
                        output_dict=obj_output_dict,
                        frame_idx=frame_idx,
                        batch_size=1,
                        is_init_cond_frame=False,
                        point_inputs=None,
                        mask_inputs=None,
                        reverse=False,
                        run_mem_encoder=True,  # å¯ç”¨è®°å¿†ç¼–ç å™¨æ›´æ–°è®°å¿†
                    )
                    obj_output_dict["non_cond_frame_outputs"][frame_idx] = current_out
                
                pred_masks_per_obj.append(pred_masks)
    
            # è¿”å›è°ƒæ•´åçš„æ©è†œ
            all_pred_masks = torch.cat(pred_masks_per_obj, dim=0)
            _, video_res_masks = self._get_orig_video_res_output(inference_state, all_pred_masks)
            yield frame_idx, obj_ids, video_res_masks
    ```
    *è¯´æ˜*ï¼šæ­¤æ–¹æ³•é¢„å¤„ç†åˆå§‹è¾“å…¥åï¼Œé€å¸§è¿½è¸ªå¯¹è±¡ã€‚å¯¹äºæ¯å¸§ï¼Œå®ƒè°ƒç”¨`_run_single_frame_inference`ï¼ˆå¯ç”¨è®°å¿†ç¼–ç å™¨ï¼‰ï¼Œåˆ©ç”¨å¯¹è±¡çš„å†å²è®°å¿†å’Œå½“å‰å¸§ç‰¹å¾é¢„æµ‹æ–°æ©è†œã€‚ç»“æœæ©è†œè°ƒæ•´åè¿”å›ï¼Œå½¢æˆè¿ç»­è¿½è¸ªã€‚

### æ€»ç»“

`SAM2VideoPredictor`æ˜¯ä¸€æ¬¾å¤æ‚ä½†ç”¨æˆ·å‹å¥½çš„å·¥å…·ï¼Œå°†SAM-2å¼ºå¤§çš„åˆ†å‰²èƒ½åŠ›ä»å•å¼ å›¾åƒæ‰©å±•åˆ°æ•´ä¸ªè§†é¢‘

é€šè¿‡ç®¡ç†æŒä¹…çš„`inference_state`å¹¶åˆ©ç”¨å†å²ä¿¡æ¯é€å¸§æ™ºèƒ½ä¼ æ’­å¯¹è±¡åˆ†å‰²ï¼Œ==å°†æ‰‹åŠ¨è§†é¢‘æ ‡æ³¨è½¬å˜ä¸ºé«˜æ•ˆçš„è‡ªåŠ¨åŒ–è¿‡ç¨‹==ã€‚å®ƒæ˜¯å¤„ç†åŠ¨æ€å¯¹è±¡æ—¶é—´ç»´åº¦çš„ç†æƒ³è§£å†³æ–¹æ¡ˆã€‚

ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»äº†è§£äº†`SAM2ImagePredictor`å’Œ`SAM2VideoPredictor`å¦‚ä½•æä¾›é«˜çº§APIä¸SAM-2äº¤äº’ï¼Œæ¥ä¸‹æ¥è®©æˆ‘ä»¬æ·±å…¥æ¢ç´¢å…¶==æ ¸å¿ƒæ™ºèƒ½==ï¼š[SAM2åŸºç¡€æ¨¡å‹](03_sam2base_model_.md)ã€‚

[ä¸‹ä¸€ç« ï¼šSAM2åŸºç¡€æ¨¡å‹](03_sam2base_model_.md)

